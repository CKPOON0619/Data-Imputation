#%% Packages
import os
import tensorflow as tf
import numpy as np
from tensorflow.keras import Model
from datetime import datetime
from os import getcwd
from components.Orchestrator import Orchestrator
from components.Discriminator import myDiscriminator
import matplotlib.pyplot as plt
#%%
def generate_random(data_batch,mask):
    random_generated=tf.random.uniform(tf.shape(data_batch),minval=0,maxval=1,dtype=tf.float32)
    return random_generated*(1-mask)+data_batch*mask
def get_generator_logLoss(discriminations,mask):
    '''
    Get the logLoss contributed for generated fake values.

    Args:
        discriminations: probability predicted by discriminator that a data entry is real.
        mask:a matrix with the same size as discriminated_probs. Entry value 1 indicate a genuine value, value 0 indicate missing(generated) value.
    Returns:
        loss value contributed by generated value imagined by the generator.
    
    '''
    ## Likelinhood loss caused by discriminable values
    return -tf.reduce_sum((1-mask) * tf.math.log(discriminations + 1e-8))/tf.reduce_sum(1-mask)
def get_test_mask(x):
    '''
    Produce a test mask for the distribution of the last column.

    Args:
        x: Input data.
    Returns:
        An array of test mask with 0 at the last entries of each row and 1 in the rest of the entries.
    '''
    shape=tf.shape(x)
    testMask=tf.tile(tf.concat([tf.ones([1,shape[1]-1],dtype=tf.float32),tf.zeros([1,1],dtype=tf.float32)],axis=1),[shape[0],1])
    return testMask

def get_last_column_scanner(x):
    shape=tf.shape(x)
    return tf.concat([tf.zeros(shape=[shape[0],shape[1]-1],dtype=tf.float32),tf.reshape(tf.range(0,1,1/shape[0],dtype=tf.float32),shape=[shape[0],1])],axis=1)
    
def get_last_column(x):
    '''
    Collect the last column of matrx x.

    Args:
        x: Input data.
    Returns:
        All last entries of each row of x.
    '''
    return tf.gather(x,[tf.shape(x)[1]-1],axis=1)
def get_generated_value_errors(mask,hint_mask,x,generated_x):
    '''
    Get the values of the generated values that are unknown to the generator.

    Args:
        mask: a matrix with the same size as discriminated_probs. Entry value 1 indicate a genuine value, value 0 indicate missing(generated) value.
        hint_mask: mask for creating hints with 1,0 values. Same size as discriminated_probs.
        x: Input data.
        generated_x: data generated by the generator.
    Returns:
        values of the generated values that are unknown to the generator.
    '''
    ## Check the difference between generated value and actual value
    return tf.gather_nd((generated_x-x),tf.where((1-mask)*(1-hint_mask)))

def get_total_generator_truth_error(data_batch,generated_data,mask):
    '''
    Get the logLoss of generated true values.

    Args:
        x: Input data.
        generated_x: generated data by the generator.
        mask:a matrix with the same size as x. Entry value 1 indicate a genuine value, value 0 indicate missing(generated) value.
        
    Returns:
        logLoss value contributed by genuine value reconstructed by the generator.
    '''
    ## Regulating term for alteration of known truth
    return tf.reduce_sum(mask*(data_batch-generated_data)**2) / tf.reduce_sum(mask)

#%%
class GAN(Orchestrator):
    '''
    GAN orchestrator for Generative Adversarial Information Net(GAIN).
    Args:
        logdir: logging directory for tensorboard. Default to be "./logs/tf_logs(dateTime)"
        hyperParams: hyperparameters for the GAN model, default to be {'p_miss': 0.5, 'alpha': 0, episode_num: 5}
                    p_miss: missing rate of data for rebalancing during training for generator
                    alpha: regulation parameters.
                    episode_num: the number of episode the discriminator would be unrolled.
        optimizer: A tensorflow optimizer class object
    '''
    def __init__(self,generator,discriminator,summary_writer=False, hyperParams={}, optimizer=tf.keras.optimizers.Adam()):
        self.discriminator=discriminator
        self.generator=generator
        self.alpha=0
        self.p_miss=0.5
        self.episode_num=5
        super().__init__(summary_writer=summary_writer, hyperParams=hyperParams, optimizer=optimizer)

    @tf.function
    def tensorboard_log(self,prefix,data_batch,mask,hints,hint_mask):
        generated_data=self.generator.generate(data_batch,mask)
        adjusted_generated_data=mask*data_batch+generated_data*(1-mask)
        
        self.discriminator.performance_log(self.summary_writer,prefix,adjusted_generated_data,hints,mask,hint_mask,self.p_miss,self.epoch)
        
        lastColMask=get_test_mask(data_batch)
        lastColHints=lastColMask+(1-lastColMask)*0.5
        lastColMasked_sample=lastColMask*data_batch+(1-lastColMask)*tf.random.uniform(tf.shape(data_batch),minval=0,maxval=1,dtype=tf.float32)
        generatedLastCol=self.discriminator.body(tf.concat(axis = 1, values = [lastColMasked_sample,lastColMask]))
        randomLastColDiscriminations=self.discriminator.discriminate(lastColMasked_sample,lastColHints)
        
        discriminated_probs=self.discriminator.discriminate(adjusted_generated_data,hints)
        generator_loss=get_generator_logLoss(discriminated_probs,mask)
        with self.summary_writer.as_default():
            tf.summary.scalar(prefix+' generator_loss', generator_loss, step=self.epoch) 
            tf.summary.scalar(prefix+' know value regeneration error', get_total_generator_truth_error(data_batch,generated_data,mask), step=self.epoch)
            tf.summary.histogram(prefix+' hidden value generation errors',get_generated_value_errors(mask,hint_mask,data_batch,generated_data), step=self.epoch) 
           
            tf.summary.histogram(prefix+' discrimination distribution of uniformly random last column',get_last_column(randomLastColDiscriminations), step=self.epoch) 
            tf.summary.histogram(prefix+' generated last column distribution',get_last_column(generatedLastCol), step=self.epoch) 
            tf.summary.histogram(prefix+' actual last column distribution',get_last_column(data_batch), step=self.epoch) 
        self.epoch.assign_add(1)
        
    def tensorboard_log_with_random(self,prefix,data_batch,mask,hints,hint_mask):
        generated_data=generate_random(data_batch,mask)
        adjusted_generated_data=mask*data_batch+generated_data*(1-mask)
        
        lastColMask=get_test_mask(data_batch)
        lastColHints=lastColMask+(1-lastColMask)*0.5
        lastColMasked_sample=lastColMask*data_batch+(1-lastColMask)*tf.random.uniform(tf.shape(data_batch),minval=0,maxval=1,dtype=tf.float32)
        randomLastColDiscriminations=self.discriminator.discriminate(lastColMasked_sample,lastColHints)
        
        self.discriminator.performance_log(self.summary_writer,prefix,adjusted_generated_data,hints,mask,hint_mask,self.p_miss,self.epoch)
        with self.summary_writer.as_default():
            tf.summary.histogram(prefix+' discrimination distribution of uniformly random last column',get_last_column(randomLastColDiscriminations), step=self.epoch) 
        
        self.epoch.assign_add(1)

    @tf.function
    def train_discriminator(self,data_batch,mask,hints,steps=1):
        '''
        A function that train generator and respective discriminator.
        Args:
            data_batch: data input.
            mask: mask of the data, 0,1 matrix of the same shape as data.
            hints: hints matrix with 1,0.5,0 values. Same shape as data.
            generator: A generator model for the GAIN structure.
            discriminator: A discriminator model for the GAIN structure.
            steps: The number of steps training the discriminator each time before training the generator.
        '''
        for i in range(0,steps):
            generated_data=self.generator.generate(data_batch,mask)
            adjusted_generated_data=mask*data_batch+generated_data*(1-mask)
            self.discriminator.train(adjusted_generated_data,mask,hints,self.p_miss,self.optimizer)
       
    @tf.function 
    def train_generator(self,data_batch,mask,hints):
        with tf.GradientTape(persistent=True) as tape:
            generated_data=self.generator.generate(data_batch,mask)
            adjusted_generated_data=generated_data*(1-mask)+mask*data_batch
            discriminations=self.discriminator.discriminate(adjusted_generated_data,hints)
            loss=get_generator_logLoss(discriminations,mask)   
        loss_gradients = tape.gradient(loss,self.generator.body.trainable_variables)
        self.optimizer.apply_gradients(zip(loss_gradients, self.generator.body.trainable_variables))


    @tf.function
    def train_generator_with_discriminator_unrolled(self,data_batch,mask,hints):
        with tf.GradientTape(persistent=True) as tape:
            generated_data=self.generator.generate(data_batch,mask)
            adjusted_generated_data=generated_data*(1-mask)+mask*data_batch
            discriminations=self.discriminator.discriminate_with_episodes(adjusted_generated_data,hints)
            losses=[]
            for discrimination in discriminations:
                losses.append(get_generator_logLoss(discrimination,mask))
            total_loss=tf.math.add_n(losses)
        loss_gradients = tape.gradient(total_loss,self.generator.body.trainable_variables)
        self.optimizer.apply_gradients(zip(loss_gradients, self.generator.body.trainable_variables))

    def discriminator_scan(self,data_batch):
        lastColMask=get_test_mask(data_batch)
        lastColHints=lastColMask+(1-lastColMask)*0.5
        
        rangeScan=tf.reshape(tf.range(0,1,1/tf.shape(data_batch)[0]+1e-12,dtype=tf.float32),[tf.shape(data_batch)[0],1])
        zeros=tf.zeros(shape=[tf.shape(data_batch)[0],tf.shape(data_batch)[1]-1],dtype=tf.float32)    
        scanner=tf.concat([zeros,rangeScan],axis=1)
        
        lastColScanner=lastColMask*data_batch+scanner
        scannedLastColCritics=self.discriminator.discriminate(lastColScanner,lastColHints)
        plt.plot(scannedLastColCritics.numpy()[:,-1])
        # np.histogram(data_batch[:,5].numpy())
        return lastColScanner,scannedLastColCritics
    
    @tf.function
    def train_discriminator_with_random(self,data_batch,mask,hints):
        '''
        A function that train discriminator with randomly generated data.
        Args:
            data_batch: data input.
            mask: mask of the data, 0,1 matrix of the same shape as data.
            hints: hints matrix with 1,0.5,0 values. Same shape as data.
            steps: The number of steps training the discriminator each time before training the generator.
        '''
        generated_data=generate_random(data_batch,mask)
        adjusted_generated_data=mask*data_batch+generated_data*(1-mask)
        self.discriminator.train(adjusted_generated_data,mask,hints,self.p_miss,self.optimizer)

    @tf.function
    def unroll_discriminator(self,data_batch,mask,hints,unrolling_steps=1):
        '''
        A function that train generator and respective discriminator.
        Args:
            data_batch: data input.
            mask: mask of the data, 0,1 matrix of the same shape as data.
            hints: hints matrix with 1,0.5,0 values. Same shape as data.
            steps: The number of steps training the discriminator each time before training the generator.
        '''
        self.discriminator.unroll(data_batch,mask,hints,self.optimizer,self.p_miss,self.alpha,steps=unrolling_steps)
            
            